from tkinter import *
from PIL import Image, ImageTk
import cv2 
from ultralytics import YOLO
import numpy as np
import time
import sys
from mss import mss
import threading
import os
import platform
import pyautogui
from pynput import mouse

# --- Configuraci√≥n global y carga del modelo ---
print("Cargando modelo YOLO con detecci√≥n normal...")

# Intentar cargar modelos normales en orden de tama√±o
model_options = [
    "yolov8n.pt",      # Modelo m√°s peque√±o y estable (ya lo tienes)
    "yolov8s.pt",      # Modelo peque√±o
    "yolov8m.pt",      # Modelo mediano
    "yolov8l.pt",      # Modelo grande
    "yolov8x.pt"       # Modelo extra grande
]

model = None
model_type = None

# Primero verificar si los archivos existen localmente
available_models = []
for model_path in model_options:
    if os.path.exists(model_path):
        available_models.append(model_path)
        print(f" Modelo encontrado localmente: {model_path}")

if not available_models:
    print(" No se encontraron modelos localmente.")
    print(" Intentando descargar autom√°ticamente...")
    print("   (Si falla, descarga manualmente desde: https://github.com/ultralytics/assets/releases)")
    available_models = model_options  # Intentar todos

# Intentar cargar los modelos disponibles
for model_path in available_models:
    try:
        print(f"Intentando cargar {model_path}...")
        # Si el archivo no existe, YOLO intentar√° descargarlo autom√°ticamente
        model = YOLO(model_path)
        model_type = model_path.replace('.pt', '')
        print(f" Modelo {model_type} cargado exitosamente!")
        break
    except Exception as e:
        error_msg = str(e)
        if "Download" in error_msg or "download" in error_msg or "curl" in error_msg.lower():
            print(f" Error descargando {model_path}: Problema de conexi√≥n o permisos")
            print(f"   Descarga manualmente desde: https://github.com/ultralytics/assets/releases/download/v8.3.0/{model_path}")
        else:
            print(f" Error cargando {model_path}: {e}")
        continue

if model is None:
    print("\n" + "="*60)
    print(" ERROR FATAL: No se pudo cargar ning√∫n modelo")
    print("="*60)
    print("\n SOLUCI√ìN: Descarga manualmente un modelo de YOLO 8")
    print("\n Descarga uno de estos modelos desde:")
    print("   https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt")
    print("   https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt")
    print("   https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt")
    print("\n Col√≥calo en el mismo directorio que este script:")
    print(f"   {os.getcwd()}")
    print("\n Luego ejecuta el script principal nuevamente.")
    print("="*60)
    sys.exit(1)

# Carga los nombres de las clases (personas, coches, etc.) del dataset COCO
classesFile = "coco.names"
try:
    with open(classesFile, 'rt') as f:
        classes = f.read().rstrip('\n').split('\n')
except FileNotFoundError:
    print(f"Error: No se encontr√≥ el archivo '{classesFile}'. Aseg√∫rate de que est√© en el mismo directorio.")
    print("Puedes descargarlo desde: https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names")
    sys.exit("Archivo coco.names faltante.")

# Genera colores aleatorios para dibujar los recuadros de las clases
COLORS = np.random.uniform(0, 255, size=(len(classes), 3))

# Configuraci√≥n de detecci√≥n normal (sin esqueletos)
# El modelo normal detecta objetos pero no keypoints de pose

# --- Configuraci√≥n de la captura de pantalla ---
sct = mss()

# Mostrar informaci√≥n de monitores disponibles
print("Monitores disponibles:")
for i, monitor in enumerate(sct.monitors):
    print(f"Monitor {i}: {monitor['width']}x{monitor['height']} en ({monitor['left']}, {monitor['top']})")

# Configurar captura del monitor 2 (pantalla que se revisa por la IA)
if len(sct.monitors) > 2:
    monitor_area = sct.monitors[2]  # Monitor 2 - pantalla que se revisa
    print(f"üìπ Capturando desde: Monitor 2 - {monitor_area['width']}x{monitor_area['height']} en ({monitor_area['left']}, {monitor_area['top']})")
else:
    # Si no hay monitor 2, usar monitor 1 como respaldo
    monitor_area = sct.monitors[1]
    print(f" Solo hay {len(sct.monitors)-1} monitor(es). Usando Monitor 1 como respaldo.")
    print(f" Capturando desde: Monitor 1 - {monitor_area['width']}x{monitor_area['height']}")

# Guardar referencia al monitor de captura para calcular coordenadas del mouse
capture_monitor = monitor_area
print(f"El mouse se mover√° en las coordenadas del monitor de captura: ({capture_monitor['left']}, {capture_monitor['top']})")

# --- Variables globales para Tkinter ---
root = None
label = None
running = True

# --- Variables globales para detecci√≥n de mouse ---
left_button_pressed = False
right_button_pressed = False
detected_boxes = []  # Almacenar los cuadrados detectados m√°s recientes
mouse_listener = None
last_mouse_move_time = 0  # Para evitar m√∫ltiples movimientos r√°pidos
MOUSE_MOVE_COOLDOWN = 0.5  # Segundos entre movimientos de mouse

# --- Configuraci√≥n de precisi√≥n ---
# Ajusta estos valores para mejorar la precisi√≥n:
CONFIDENCE_THRESHOLD = 0.25  # Umbral de confianza m√°s bajo para detectar m√°s (0.1-1.0)
IOU_THRESHOLD = 0.2          # Umbral de IoU m√°s bajo para detectar m√°s (0.1-0.9)
CLASSES_TO_DETECT = [0]      # 0 = persona, puedes agregar m√°s clases si quieres
MAX_DETECTIONS = 50          # M√°ximo n√∫mero de detecciones (aumentado de 20 a 50)

print(f"Configuraci√≥n de precisi√≥n:")
print(f"- Confianza m√≠nima: {CONFIDENCE_THRESHOLD}")
print(f"- IoU threshold: {IOU_THRESHOLD}")
print(f"- M√°ximo detecciones: {MAX_DETECTIONS}")
print(f"- Clases detectadas: {CLASSES_TO_DETECT}")
print(f"- Modelo usado: {model_type}")

# --- Funciones para detecci√≥n de mouse ---
def on_mouse_click(x, y, button, pressed):
    """Callback para detectar clicks del mouse"""
    global left_button_pressed, right_button_pressed, last_mouse_move_time
    
    if button == mouse.Button.left:
        left_button_pressed = pressed
    elif button == mouse.Button.right:
        right_button_pressed = pressed
    
    # Si ambos botones est√°n presionados simult√°neamente, mover el mouse al cuadrado m√°s cercano
    current_time = time.time()
    if (left_button_pressed and right_button_pressed and 
        len(detected_boxes) > 0 and 
        (current_time - last_mouse_move_time) > MOUSE_MOVE_COOLDOWN):
        move_mouse_to_nearest_box(x, y)
        last_mouse_move_time = current_time
    
    return True  # Continuar escuchando

def move_mouse_to_nearest_box(current_x, current_y):
    """Mueve el mouse al centro del cuadrado detectado m√°s cercano en la pantalla de captura (Monitor 2)"""
    global detected_boxes, capture_monitor
    
    if not detected_boxes:
        return
    
    # Obtener posici√≥n actual del mouse
    try:
        current_mouse_x, current_mouse_y = pyautogui.position()
    except:
        current_mouse_x, current_mouse_y = current_x, current_y
    
    # Encontrar el cuadrado m√°s cercano al cursor actual
    min_distance = float('inf')
    nearest_box_center = None
    
    for box in detected_boxes:
        # Calcular centro del bounding box en coordenadas relativas al frame capturado
        center_x_relative = (box['x1'] + box['x2']) // 2
        center_y_relative = (box['y1'] + box['y2']) // 2
        
        # Convertir a coordenadas absolutas de la pantalla de captura (Monitor 2)
        # Las coordenadas relativas del frame se corresponden directamente con las coordenadas del monitor
        screen_x = capture_monitor['left'] + center_x_relative
        screen_y = capture_monitor['top'] + center_y_relative
        
        # Calcular distancia desde la posici√≥n actual del mouse (no desde el click)
        distance = ((current_mouse_x - screen_x) ** 2 + (current_mouse_y - screen_y) ** 2) ** 0.5
        
        if distance < min_distance:
            min_distance = distance
            nearest_box_center = (screen_x, screen_y)
    
    if nearest_box_center:
        try:
            # Mover el mouse a las coordenadas absolutas en la pantalla de captura
            pyautogui.moveTo(nearest_box_center[0], nearest_box_center[1], duration=0.1)
            print(f" Mouse movido a: ({nearest_box_center[0]}, {nearest_box_center[1]}) en Monitor de Captura")
            print(f"   Coordenadas relativas en frame: ({(nearest_box_center[0] - capture_monitor['left'])}, {(nearest_box_center[1] - capture_monitor['top'])})")
        except Exception as e:
            print(f" Error moviendo el mouse: {e}")

def start_mouse_listener():
    """Inicia el listener de mouse en un hilo separado"""
    global mouse_listener
    try:
        mouse_listener = mouse.Listener(on_click=on_mouse_click)
        mouse_listener.start()
        print(" Listener de mouse iniciado. Presiona click izquierdo + derecho para mover el mouse al cuadrado detectado.")
    except Exception as e:
        print(f" Error iniciando listener de mouse: {e}")
        print(" La funcionalidad de movimiento de mouse no estar√° disponible.")

# --- Funciones ---
def onClossing():
    """Funci√≥n para limpiar y cerrar la aplicaci√≥n al cerrar la ventana."""
    global running, mouse_listener
    print("Cerrando aplicaci√≥n...")
    running = False
    
    # Detener el listener de mouse
    if mouse_listener:
        mouse_listener.stop()
    
    # Detener el bucle principal de Tkinter y destruir la ventana
    if root:
        root.quit()
        root.destroy()
    
    # Forzar salida del programa
    os._exit(0)

def process_frame():
    """
    Funci√≥n que procesa frames en un hilo separado para mejor rendimiento
    """
    global running, label, detected_boxes
    
    # Crear una nueva instancia de mss en este hilo
    thread_sct = mss()
    
    while running:
        try:
            last_time = time.time()  # Para calcular FPS

            # 1. Capturar la pantalla del monitor principal usando la instancia del hilo
            sct_img = thread_sct.grab(monitor_area)
            frame = np.array(sct_img)
            # Convertir de RGBA (mss) a BGR (OpenCV)
            frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)
            
            # Opcional: Redimensionar para mejor rendimiento/precisi√≥n
            # frame = cv2.resize(frame, (640, 480))  # Descomenta para mejor rendimiento
            # frame = cv2.resize(frame, (1280, 720)) # Descomenta para mejor precisi√≥n
            
            frame_for_yolo = frame.copy()  # Usar el frame original para YOLO

            # 2. Realizar la detecci√≥n con YOLO con par√°metros optimizados y manejo de errores
            try:
                results = model.predict(
                    frame_for_yolo,
                    verbose=False,
                    conf=CONFIDENCE_THRESHOLD,
                    classes=CLASSES_TO_DETECT,
                    iou=IOU_THRESHOLD,
                    agnostic_nms=True,  # Mejor para detecci√≥n de personas
                    max_det=MAX_DETECTIONS  # M√°ximo n√∫mero de detecciones
                )
            except Exception as predict_error:
                print(f"Error en predicci√≥n: {predict_error}")
                # Continuar con el siguiente frame
                time.sleep(0.01)
                continue
            
            # Crear un frame negro del mismo tama√±o
            height, width = frame.shape[:2]
            annotated_frame = np.zeros((height, width, 3), dtype=np.uint8)
            
            # Contador de objetos detectados
            detection_count = 0
            person_count = 0  # Contador espec√≠fico para personas
            # Limpiar lista de cuadrados detectados para este frame
            detected_boxes.clear()
            
            # Procesar resultados
            for result in results:
                boxes = result.boxes
                
                if boxes is not None:
                    for i, box in enumerate(boxes):
                        try:
                            # Obtener coordenadas del bounding box
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            confidence = box.conf[0].cpu().numpy()
                            class_id = int(box.cls[0].cpu().numpy())
                            
                            # Verificar si la clase est√° en la lista de clases a detectar
                            if class_id in CLASSES_TO_DETECT:
                                detection_count += 1
                                
                                # Contar personas espec√≠ficamente
                                if class_id == 0:  # 0 = persona en COCO
                                    person_count += 1
                                
                                # Convertir coordenadas a enteros
                                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                                
                                # Guardar el cuadrado detectado para movimiento de mouse
                                detected_boxes.append({
                                    'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2,
                                    'confidence': confidence
                                })
                                
                                # Convertir color a tupla para evitar problemas
                                color_tuple = tuple(map(int, COLORS[class_id]))
                                
                                # Dibujar el bounding box en el frame negro
                                cv2.rectangle(annotated_frame,
                                            (x1, y1),
                                            (x2, y2),
                                            color_tuple, 3)
                                
                                # Agregar texto con fondo negro para mejor visibilidad
                                class_name = classes[class_id] if class_id < len(classes) else f"Clase {class_id}"
                                label_text = f"{class_name}: {confidence:.2f}"
                                
                                # Obtener el tama√±o del texto
                                (text_width, text_height), baseline = cv2.getTextSize(
                                    label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2
                                )
                                
                                # Dibujar rect√°ngulo de fondo para el texto
                                cv2.rectangle(annotated_frame,
                                            (x1, y1 - text_height - 10),
                                            (x1 + text_width, y1),
                                            (0, 0, 0), -1)
                                
                                # Agregar texto
                                cv2.putText(annotated_frame, label_text,
                                          (x1, y1 - 5),
                                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, color_tuple, 2)
                        except Exception as box_error:
                            print(f"Error procesando bounding box: {box_error}")
                            continue
            
            # Calcular FPS
            fps = 1 / (time.time() - last_time)
            
            # Agregar informaci√≥n en la esquina superior izquierda
            info_text = f"FPS: {int(fps)} | Personas: {person_count} | {model_type.upper()}"
            cv2.putText(annotated_frame, info_text, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

            # 3. Preparar el frame para Tkinter
            img_tk = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
            img_tk = Image.fromarray(img_tk)
            tkimage = ImageTk.PhotoImage(img_tk)
            
            # Actualizar el Label de Tkinter de forma segura
            if root and running:
                root.after(0, lambda img=tkimage: update_label(img))
            
            # Peque√±a pausa para no saturar el CPU
            time.sleep(0.01)

        except Exception as e:
            print(f"Error en el bucle principal: {e}")
            import traceback
            traceback.print_exc()
            time.sleep(1)  # Pausa m√°s larga en caso de error
            continue

def update_label(tkimage):
    """Funci√≥n para actualizar el label de forma segura"""
    global label
    if label and running:
        label.configure(image=tkimage)
        label.image = tkimage

# --- Inicializaci√≥n de la Interfaz Gr√°fica (Tkinter) ---
root = Tk()
root.protocol("WM_DELETE_WINDOW", onClossing)
root.title(f"Detecci√≥n de Personas en Pantalla ({model_type.upper()})")

# Configurar la ventana para que aparezca en un monitor diferente al de captura
# La visualizaci√≥n debe estar en otro monitor, no en el monitor de captura (Monitor 2)
display_monitor = None

if len(sct.monitors) > 2:
    # Verificar si estamos capturando del Monitor 2 comparando coordenadas
    is_capturing_monitor_2 = (capture_monitor['left'] == sct.monitors[2]['left'] and 
                               capture_monitor['top'] == sct.monitors[2]['top'] and
                               capture_monitor['width'] == sct.monitors[2]['width'] and
                               capture_monitor['height'] == sct.monitors[2]['height'])
    
    if is_capturing_monitor_2:
        # Si capturamos del Monitor 2, mostrar en Monitor 1
        display_monitor = sct.monitors[1]
        print(f"üì∫ Visualizaci√≥n en Monitor 1 (diferente al Monitor 2 de captura)")
    else:
        # Si capturamos del Monitor 1, intentar usar Monitor 2 si existe
        if len(sct.monitors) > 2:
            display_monitor = sct.monitors[2]
            print(f"üì∫ Visualizaci√≥n en Monitor 2 (diferente al Monitor 1 de captura)")
        else:
            display_monitor = sct.monitors[1]
            print(f"üì∫ Visualizaci√≥n en Monitor 1")
    
    if display_monitor:
        root.geometry(f"+{display_monitor['left']}+{display_monitor['top']}")
        print(f"   Posici√≥n: ({display_monitor['left']}, {display_monitor['top']})")
        print(f"   Tama√±o: {display_monitor['width']}x{display_monitor['height']}")
    else:
        # Si no hay otro monitor, posicionar al lado del monitor de captura
        root.geometry(f"+{capture_monitor['left'] + capture_monitor['width']}+{capture_monitor['top']}")
        print(f" Visualizaci√≥n al lado del monitor de captura")
else:
    # Si solo hay un monitor, posicionar al lado
    display_monitor = sct.monitors[1] if len(sct.monitors) > 1 else None
    if display_monitor:
        root.geometry(f"+{display_monitor['left']}+{display_monitor['top']}")
    else:
        root.geometry(f"+{capture_monitor['left'] + capture_monitor['width']}+{capture_monitor['top']}")
    print(f" Solo hay un monitor. Visualizaci√≥n al lado del monitor de captura")

# Hacer la ventana de pantalla completa (compatible con Windows y Linux)
system_os = platform.system()
if system_os == 'Windows':
    root.state('zoomed')  # En Windows
elif system_os == 'Linux':
    root.attributes('-zoomed', True)  # En Linux
else:
    # Para macOS u otros sistemas
    root.attributes('-zoomed', True)

# Configurar para que est√© siempre al frente
root.attributes('-topmost', True)

label = Label(root)
label.grid(row=0, column=0, padx=10, pady=10)

# --- Inicio del procesamiento ---
try:
    print("\n" + "="*60)
    print("üöÄ Iniciando detecci√≥n de personas")
    print("="*60)
    print(f"üìπ Monitor de CAPTURA (revisado por IA):")
    print(f"   - Monitor 2: {capture_monitor['width']}x{capture_monitor['height']}")
    print(f"   - Posici√≥n: ({capture_monitor['left']}, {capture_monitor['top']})")
    print(f"\nüì∫ Monitor de VISUALIZACI√ìN (donde se muestran los cuadros):")
    if display_monitor:
        # Determinar qu√© n√∫mero de monitor es
        monitor_number = None
        for i, mon in enumerate(sct.monitors):
            if (mon['left'] == display_monitor['left'] and 
                mon['top'] == display_monitor['top'] and
                mon['width'] == display_monitor['width'] and
                mon['height'] == display_monitor['height']):
                monitor_number = i
                break
        
        if monitor_number is not None:
            print(f"   - Monitor {monitor_number}: {display_monitor['width']}x{display_monitor['height']}")
            print(f"   - Posici√≥n: ({display_monitor['left']}, {display_monitor['top']})")
        else:
            print(f"   - Tama√±o: {display_monitor['width']}x{display_monitor['height']}")
            print(f"   - Posici√≥n: ({display_monitor['left']}, {display_monitor['top']})")
    else:
        print(f"   - Mismo monitor de captura")
    print(f"\nüñ±Ô∏è Movimiento del mouse:")
    print(f"   - El mouse se mover√° en el Monitor de CAPTURA (Monitor 2)")
    print(f"   - Las coordenadas son proporcionales al monitor de captura")
    print(f"   - Los cuadros se muestran en otro monitor (visualizaci√≥n)")
    print(f"\nüíª Sistema operativo: {system_os}")
    print("="*60)
    print("\n Instrucciones:")
    print("   1. Los cuadros de detecci√≥n se muestran en el monitor de visualizaci√≥n")
    print("   2. Presiona click IZQUIERDO + DERECHO simult√°neamente")
    print("   3. El mouse se mover√° al centro de la persona detectada m√°s cercana")
    print("   4. El movimiento ocurre en el Monitor 2 (monitor de captura)")
    print("   5. Presiona Ctrl+C en la consola para cerrar el programa")
    print("="*60 + "\n")

    # Iniciar el listener de mouse
    start_mouse_listener()

    # Iniciar el procesamiento en un hilo separado
    processing_thread = threading.Thread(target=process_frame, daemon=True)
    processing_thread.start()

    # Iniciar el bucle principal de Tkinter
    root.mainloop()

except Exception as e:
    print(f"Error al iniciar Tkinter: {e}")

    onClossing()
